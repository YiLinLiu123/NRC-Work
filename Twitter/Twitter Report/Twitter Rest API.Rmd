---
title: "Twitter Rest API"
author: "paul"
date: "March 14, 2017"
output: 
    html_document:
        toc: true
        toc.depth: 6
        
     pdf_document:
        toc:true
        toc.depth: 6
---



*****

### Tools and Packages:
*   [Apigee Twitter API Console](https://apigee.com/console/twitter)
    +   Useful interface to test out queries to the API.
*   [twitteR](https://cran.r-project.org/web/packages/twitteR/index.html)
*   [twitteR Vignette](http://geoffjentry.hexdump.org/twitteR.pdf)
    +   __Highly Recommended to Read__



*****

### Evaluation of _twitteR_ and __REST API__:

___Advantages:___
*   The built-in class wrappers provides
    convenient and organized information. 
    +   functions associated with these class
        are very useful. like `user$id` etc.
*   Even though the package does not support
    custom requests, most information
    of interest is provided by default.
*   The built-in function for classes provides substantial 
    details and is shown in an easily accessible
    way.
*   Unlike Facebook, many users & tweets are public and thus
    the account details and tweets are easily accessed.
    
*****

___Disadvantages:___
*   However it is difficult to track a conversation 
    and reactions to a post because it is not directly
    related to the original tweet.
*   The token generated by the package is cached somewhere 
    that can be used by the _twitteR_ package functions through 
    out the session. However if another package requires access 
    to the token, it is not easily accessible.
*   Tweets are often truncated in response unless 
    specified. The built-in functions does not seem to 
    support extracting untruncated tweets.


*****

### Tweeter Limits And Information:
*   Can extract up to a maximum 3200 statuses from a user Timeline.
    +   Each page of response can contain up to 200 results. 
*   For [search/tweets](https://dev.twitter.com/rest/reference/get/search/tweets), each page of response
    can contain up to 100 tweets.
*   The _source owner_ is mentioned in the text of the tweet (status in twitteR package) by an _@_ sign followed
    by the source owner of the tweet. 
*   URLs are often reported in twitter short hand, _twitteR_ 
    provides functionality to expand into URL and vice-versa.
    
    
    


***** 


### Example 1: Creating a Word Cloud From Twitter 

__GOAL: To test out the _twitteR_ package's ability to
    scrape public twitter data.__

*   [Google Building wordCloud](https://sites.google.com/site/miningtwitter/questions/talking-about/wordclouds/wordcloud1)
*   [ Building wordCloud](https://www.r-bloggers.com/building-wordclouds-in-r/)
*   [Using tm Package](https://cran.r-project.org/web/packages/tm/vignettes/tm.pdf)
    
1:  Import Libraries and getting Access Token
```{r AAA Example1: libraries, results = "hide",message= FALSE, warning=FALSE}
    
    rm(list = ls())

    library(twitteR)
    library(httr)

    library(tm)
    library(wordcloud)
    library(SnowballC)
    library(RColorBrewer)
```

```{r AAA Example 1: connections}
    # access Tokens
    consumer_Key = "oQ3PqERg75kPtgBcgOLaFShSC"
    consumer_Secret = "d4cxaKc1Dt3ugagruUNPtWzvmqGHx8WvwYAQ8MywUqTIVTTj9O"
    access_Token = "833674399224061952-tL4gGOyGUrz84IbVlkkAmQzqUPahL1N"
    access_Secret = "qkNmkD7TU5uZtIENW3r5K20wkqfbL6w37xyXLwelYBZg6"
    
    
    ##  Intially, the function asks the user to cache the credentials and 
    ##  will be used for another session.
    setup_twitter_oauth(consumer_Key,consumer_Secret,access_Token,access_Secret)
    
    
    
    ##  Creating a token manually
    app <- oauth_app("twitter", key=consumer_Key, secret=consumer_Secret)

    token = Token1.0$new(endpoint = NULL, params = list(as_header = TRUE),
                                app = app, credentials = list(oauth_token = access_Token,
                      oauth_token_secret = access_Secret))
    saveRDS(token,"tokenTest")
    test_Token = readRDS("tokenTest")
    
    ## token and test_Token are the same object.
    
    ## loading cached token from twitteR package:
    ##  It failed, likely because of the output format.
    ##  The file size is 0KB
   # oauth_content <- readRDS('.httr-oauth')

    
```

2:  Getting Raw Data

```{r AAA Example1: Getting Raw Data}

    ##  Some parameters
    search_String = "NRC+OR+#NRC+OR+@NRC"
    lang = "en"
    since = "2016-01-01"
   
    
    ##  Extracting coordinates for center of Canada:
    google_Api_Key = "AIzaSyBGTs-gZCbyP8n0Hvw_VZ76Z6YrST1DNa8"
    google_Host = "https://maps.googleapis.com/maps/api"
    
    request = paste(google_Host,"/geocode/json",
                    "?address=Canada&key=",
                    google_Api_Key,sep="")
    raw= GET(request)
    
    data = jsonlite::fromJSON(
       httr:: content(raw,as="text")
        )
    lat = data$results$geometry$location["lat"]
    lng = data$results$geometry$location["lng"]
    
    geocode =paste(lat,lng,"2000km",sep=",")
    
    
     
    ##  A list of tweets in Ottawa mentioning NRC. Note, the return 
    ## already a "status"
    NRC_Search = searchTwitter(search_String, n=200, 
                               lang=lang, since=since,geocode =geocode)
    
    ##  built in functions allow the specification of "untruncated tweets"
    ##  This was done manually.
    
    
    ##  Many tweets are truncated. Getting a list
    ## of ids for tweets that have been truncated.
    
    truncated_Id = lapply(NRC_Search, function(x)
            {
                if(x$truncated)
                   return(x$id)
                else
                    return(NA)
            }
        )
    
    version = 1.1
    cmd = "/statuses/show/"
    param = "?tweet_mode=extended"
    
    search_Id = truncated_Id[
        !is.na(truncated_Id)]
    
    long_Tweet = list();
    
    ##  Getting Untruncated tweets
    ##  Going to use the GET method
    for(i in 1:length(search_Id))
    {
        url = paste("https://api.twitter.com/",
                    version,cmd,
                    search_Id[i],".json",
                    param, sep="")
        
        ##getting raw response
        raw_Response = GET(url,config=token)
        
        ##  expanded
        long_Tweet[[i]] = jsonlite::fromJSON(
            httr::content(raw_Response,"text")
        )
        
    }
    
    
    truncated_Id[!is.na(truncated_Id)] = long_Tweet
    
    ## Organized texts results
    for(i in 1:length(NRC_Search)){
        if(NRC_Search[[i]]$truncated){
            NRC_Search[[i]] = truncated_Id[[i]]

        }
    }
    
    
    ## removing twitter links
    text_NRC = lapply(NRC_Search, function(x)
            {
                text = x$text
                ## converting to ASCII
                text= iconv(x=text,from="UTF-8",to="ASCII",sub="")
                
                ##Clearing out URLs
                text=gsub("http(s?)://t.co/[a-zA-Z0-9]+", 
                     "",text)
                text=gsub("\nhttps:","",text)
            }
        )
    
    
    
     # rm(list = setdiff(ls(),c("token","text_NRC")))
    
```


3:  Make the word Map
```{r AAA Example1: Making Word Map}
    require(twitteR)
    ##  Constructing corpus (structure to process text)
    cor= Corpus(VectorSource(text_NRC))
    cor = tm_map(cor,removePunctuation)
    cor = tm_map(cor, removeWords,stopwords('english'))
    cor = tm_map(cor,stemDocument)
    
    
    
    ## Some words may appear to be missing characters
    ## This is due to the stem analysis function.
    
    wordcloud(cor,max.words = 100,random.color=T,random.order = T,
              colors =brewer.pal(8,"Paired") )
```


*****

### REST API Example 2: Random Exploration 

*   The code for testing is not shown,
refer to markdown documents for the code.

```{r REST Example2:}

    ## Useful for examining rate late
    ## remaining in 15 window
    rate_Limit = getCurRateLimitInfo()

```


1:  Friendships and Users
*   __The _lookupUsers_ and _friendships_ function
    behaves as specified by the documentation.__

```{r REST Example2: Users And Information, echo=FALSE,eval=FALSE}

    ##  screen names can be found by looking under the profile
    ## picture on twitter, denoted by the @ follwed by the screen name
    screen_Name = c("NRC_API_Testing","CNN",
        "DarrenCriss","CTVNews","MasterChef")

    ## object "users" automatically returned
    users = lookupUsers(users= screen_Name)

    # examining friendship data
    friendships = lapply(users, function(x)
    {
        friendships(screen_names=x$screenName)
    })
    
    # One user
    test_User = users[[2]]
    
    friends = test_User$getFriends()
    
```

2:  Favorites:
 __The _favorites_ function
    behaves as specified by the documentation.__

```{r REST Example2: Favorites, echo=FALSE,eval=FALSE}

    
    username="NRC_API_Testing"
    
    ##  first 50 favorite posts, 
    ## only 1 post was favorited, only returned 1 element,
    ## instead of a list of NULLS or NAs for the remaining
    ## elements.
    my_Favorites = favorites(user=username, n=50)
    
```


3:  Trending Section of Twitter:
*   __the trending section describes the popular
    live disscussions and behaves as the
    documentation specifies.__
    
```{r REST Example2: Trending, echo=FALSE,eval=FALSE}

    google_Api_Key = "AIzaSyBGTs-gZCbyP8n0Hvw_VZ76Z6YrST1DNa8"
    google_Host = "https://maps.googleapis.com/maps/api"
    
    ##  A list of available trend locations
    locations = availableTrendLocations()
    
    ##  Closest trending location
    request = paste(google_Host,"/geocode/json",
                    "?address=Ottawa,Canada&key=",
                    google_Api_Key,sep="")
    raw= GET(request)
    
    data = jsonlite::fromJSON(
       httr:: content(raw,as="text")
        )
    ottawa_Lat = data$results$geometry$location["lat"]
    ottawa_Lng = data$results$geometry$location["lng"]
    closest_Location = closestTrendLocations(lat=ottawa_Lat,
                                             long=ottawa_Lng)
    
    
    ##  The following returns names and search URLs
    trend = getTrends(closest_Location$woeid)
  
    ##  Using the Search API to retrieve information
    search_Data = searchTwitter(searchString=trend$query[[2]],n=10,
                                lang="en")
    
  rm(list=setdiff(ls(),c("token","search_Data")))

```


*****

### Example 3: DataBase Connection Functions of twitteR:
*   The functionality provided by twitteR package behaves 
    as the documentation outlines. To view testing code, 
    refer to the _Twitter Rest API.Rmd_ file.


```{r Example 3: Saving data}
    library(twitteR)
    search_Data = searchTwitter(searchString="sports",n=10,
                                lang="en")
    
    db_Data = twitteR::twListToDF(search_Data)
    
      ##sorting text in search_Data
    for(i in 1: length(db_Data$text)){
        db_Data[[i]] = gsub(pattern="\n", replacement = " ",
                            db_Data[[i]])
    }


    if(!file.exists("DB_Data.txt"))
    {
        file.create("DB_Data.txt")
       
    }

     write.table(db_Data, file="./DB_Data.txt",row.names = F,
                fileEncoding = "UTF-8",sep="\t",col.names=F)

```





*   A very simple database containing the 10 tweets from the _db_Data_ 
    and stored it in a local sql data base. 
    
```{r REST Example 3: libraries,message=FALSE, warning= FALSE}
require(RMySQL)
require(twitteR)

```

```{r REST Example 3: MySqlData}



    db_name = "twitterdb"
    user = "root"
    host ="localhost"
    password = "19970728Paul$"
    
    ## sets up a connection
    DBI = register_mysql_backend(db_name,host,user,password)

    ## returns a list of twitteR status
    loaded_Data = load_tweets_db(table_name = "status")
    paste("Length", length(loaded_Data))
```


```{r REST Example 3: saving to Db}
    
    ## Trying to store tweets into the same db:
      search_Data2 = searchTwitter(searchString="#glee",n=10,
                                lang="en")
      
    ## The new data is appended to the bottom 
    store_tweets_db(search_Data2,table_name="status")
    
    loaded_Data = load_tweets_db(table_name = "status")
    paste("Length", length(loaded_Data))
    
    
```



*****

### REST API Example 4: Tweets maximum:
__GOAL: Test to see how many tweets can twitter return.__
*   The maximum number of tweets is 3200. 
    
```{r REST API Example 4: Maximum, eval=FALSE, echo=FALSE, eval=FALSE}

    rm(list = setdiff(ls(),c("token")))

    require(twitteR)

    ## Creation date of Twitter
    max = 2000
    not_Max = TRUE
    
    while(not_Max == TRUE)
    {
         test = searchTwitter(searchString="CNN",n=max)
         
         if(length(test) < max)
         {
             not_Max == FALSE;
             max = length(test)
         }
             
         else
             max= max+200;
         
         print(Sys.time())
             
    }
   
    
    
    dates =lapply(time_Test,function(x){
                x$created
            }
        )


```



